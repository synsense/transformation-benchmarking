{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import tonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_tensors = [(torch.rand((2,20,20)) < 0.1).float() for i in range(20)]\n",
    "dataset = [tensor.to_sparse() for tensor in dense_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Caught NotImplementedError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 139, in default_collate\n    storage = elem.storage()._new_shared(numel, device=elem.device)\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/_tensor.py\", line 206, in storage\n    return torch._TypedStorage(wrap_storage=self._storage(), dtype=self.dtype)\nNotImplementedError: Cannot access storage of SparseTensorImpl\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/gregorlenz/Development/tonic-benchmarking/sparse-tensors-gpu/sparse-tensor-loading.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsynsense-riverlake/home/gregorlenz/Development/tonic-benchmarking/sparse-tensors-gpu/sparse-tensor-loading.ipynb#ch0000002vscode-remote?line=0'>1</a>\u001b[0m dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(dataset, num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsynsense-riverlake/home/gregorlenz/Development/tonic-benchmarking/sparse-tensors-gpu/sparse-tensor-loading.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dataloader))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsynsense-riverlake/home/gregorlenz/Development/tonic-benchmarking/sparse-tensors-gpu/sparse-tensor-loading.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m sample\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/_utils.py:475\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 475\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Caught NotImplementedError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 139, in default_collate\n    storage = elem.storage()._new_shared(numel, device=elem.device)\n  File \"/home/gregorlenz/anaconda3/envs/sparse-tensor-test/lib/python3.10/site-packages/torch/_tensor.py\", line 206, in storage\n    return torch._TypedStorage(wrap_storage=self._storage(), dtype=self.dtype)\nNotImplementedError: Cannot access storage of SparseTensorImpl\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, num_workers=4, shuffle=True)\n",
    "\n",
    "sample = next(iter(dataloader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('slayer-comparison')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6cb2531ff3209080f8ff5f4f1b83a3f6fd522559ade981afeb04664418b3902"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
